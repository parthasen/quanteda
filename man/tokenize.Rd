% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/tokenize.R
\name{tokenize}
\alias{tokenise}
\alias{tokenize}
\alias{tokenize.character}
\alias{tokenize.corpus}
\title{tokenize a set of texts}
\usage{
tokenize(x, ...)

\method{tokenize}{character}(x, simplify = FALSE, sep = " ", ...)

\method{tokenize}{corpus}(x, ...)
}
\arguments{
\item{x}{The text(s) or corpus to be tokenized}

\item{...}{additional arguments passed to \code{\link{clean}}}

\item{simplify}{If \code{TRUE}, return a character vector of tokens rather
than a list of length \code{\link{ndoc}(texts)}, with each element of the
list containing a character vector of the tokens corresponding to that
text.}

\item{sep}{by default, tokenize expects a "white-space" delimiter between
tokens. Alternatively, \code{sep} can be used to specify another character
which delimits fields.}
}
\value{
A list of length \code{\link{ndoc}(x)} of the tokens found in each text.
}
\description{
Tokenize the texts from a character vector or from a corpus.
}
\examples{
# same for character vectors and for lists
tokensFromChar <- tokenize(inaugTexts)
tokensFromCorp <- tokenize(inaugCorpus)
identical(tokensFromChar, tokensFromCorp)
str(tokensFromChar)
# returned as a list
head(tokenize(inaugTexts[57])[[1]], 10)
# returned as a character vector using simplify=TRUE
head(tokenize(inaugTexts[57], simplify=TRUE), 10)

# demonstrate some options with clean
head(tokenize(inaugTexts[57], simplify=TRUE, lower=FALSE), 30)
}

